{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('E:\\\\HCL_Technical_Lead\\\\SIE_OSIV_HCL_TRAINING\\\\PYTHON_DS_DE\\Machine_learning_zoomcamp_DATAtalks\\\\week-06-trees\\\\data\\\\jamb_exam_results.csv')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Drop student_id and fill missing values\n",
    "df = df.drop(columns=['student_id']).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 60/20/20 split\n",
    "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=1)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Separate target variable 'jamb_score'\n",
    "y_train = df_train.jamb_score.values\n",
    "y_val = df_val.jamb_score.values\n",
    "y_test = df_test.jamb_score.values\n",
    "\n",
    "# Drop target variable from the features\n",
    "df_train = df_train.drop(columns=['jamb_score'])\n",
    "df_val = df_val.drop(columns=['jamb_score'])\n",
    "df_test = df_test.drop(columns=['jamb_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert data to dictionaries for DictVectorizer\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "test_dict = df_test.to_dict(orient='records')\n",
    "\n",
    "# Use DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)\n",
    "X_test = dv.transform(test_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature used for splitting: study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train model with max_depth=1\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Find the feature used for splitting\n",
    "feature_names = dv.get_feature_names_out()\n",
    "feature_used = feature_names[dt.tree_.feature[0]]\n",
    "print(\"Feature used for splitting:\", feature_used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 43.157758977963624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train a RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate RMSE\n",
    "y_pred = rf.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators and RMSE values: [(10, 43.157758977963624), (20, 41.79043981582391), (30, 41.555818472133225), (40, 41.075631652173044), (50, 40.9571573818301), (60, 40.77368529456223), (70, 40.587805985220214), (80, 40.5027042403498), (90, 40.43492224596255), (100, 40.36491034549687), (110, 40.347525479439874), (120, 40.30191844844362), (130, 40.285789466741), (140, 40.26346078629849), (150, 40.25426440073703), (160, 40.1996656828838), (170, 40.187325737485885), (180, 40.13596272032919), (190, 40.15216599857013), (200, 40.138465594427)]\n"
     ]
    }
   ],
   "source": [
    "rmse_values = []\n",
    "for n in range(10, 201, 10):\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_values.append((n, rmse))\n",
    "\n",
    "# Find n_estimators where RMSE stops improving\n",
    "print(\"n_estimators and RMSE values:\", rmse_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 10\n"
     ]
    }
   ],
   "source": [
    "depth_rmse = {}\n",
    "for depth in [10, 15, 20, 25]:\n",
    "    rmse_list = []\n",
    "    for n in range(10, 201, 10):\n",
    "        rf = RandomForestRegressor(n_estimators=n, max_depth=depth, random_state=1, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmse_list.append(rmse)\n",
    "    depth_rmse[depth] = np.mean(rmse_list)\n",
    "\n",
    "# Find the best max_depth\n",
    "best_depth = min(depth_rmse, key=depth_rmse.get)\n",
    "print(\"Best max_depth:\", best_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important feature: study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "# Train model with given parameters\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_importances = dict(zip(dv.get_feature_names_out(), importances))\n",
    "most_important_feature = max(feature_importances, key=feature_importances.get)\n",
    "print(\"Most important feature:\", most_important_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE with eta=0.3: 40.68821969954672\n",
      "Best RMSE with eta=0.1: 40.166449496198915\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Prepare DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Watchlist for evaluation\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "# Parameters for eta=0.3\n",
    "params_03 = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "model_03 = xgb.train(params_03, dtrain, 100, evals=watchlist, early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "# Parameters for eta=0.1\n",
    "params_01 = params_03.copy()\n",
    "params_01['eta'] = 0.1\n",
    "model_01 = xgb.train(params_01, dtrain, 100, evals=watchlist, early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "# Retrieve the best scores for each model\n",
    "best_rmse_03 = model_03.best_score\n",
    "best_rmse_01 = model_01.best_score\n",
    "\n",
    "# Compare results\n",
    "print(\"Best RMSE with eta=0.3:\", best_rmse_03)\n",
    "print(\"Best RMSE with eta=0.1:\", best_rmse_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_AI_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
